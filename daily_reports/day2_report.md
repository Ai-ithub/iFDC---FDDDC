
# نام و نام خانوادگی:امین مقدم
**حوزه فعالیت:** هوش مصنوعی
**تاریخ:** ۱۴۰۳/۰۴/۲۳  
**شماره گزارش:** ۲  

---

##  ادامه مطالعات – بررسی فایل `preprocces_pipeline.py`

در روز دوم تمرکز اصلی روی بررسی و تحلیل ساختار و عملکرد فایل `preprocces_pipeline.py` بود. این فایل مسئول آماده‌سازی و تمیز کردن داده‌ها پیش از ارسال به مدل‌های یادگیری ماشین است.

###  عملکرد کلی فایل:
- **ورودی:** فایل CSV از مسیر `dataset/` با ویژگی‌های فنی حفاری مانند: `rpm`, `spp`, `flow_rate`, `ecd`, `temperature`, و غیره.
- **مراحل پردازش:**
  1. بررسی داده‌های گمشده (null values) و حذف یا جایگزینی آن‌ها
  2. بررسی محدوده معتبر برای هر ویژگی (مثلاً `0 < flow_rate < 1500`)
  3. نرمال‌سازی یا مقیاس‌بندی برخی ویژگی‌ها (در صورت نیاز)
  4. برچسب‌گذاری داده‌های خراب (anomalous tagging)
  5. ذخیره خروجی پاک‌سازی‌شده در مسیر `data/clean_data.csv`

###  کدهای مهم:
```python
df = pd.read_csv("dataset/raw_data.csv")
df.dropna(inplace=True)
df = df[(df["flow_rate"] > 0) & (df["flow_rate"] < 1500)]
df.to_csv("data/clean_data.csv", index=False)
```

---

##  یافته‌های مهم:
- فایل فاقد تست‌های دقیق برای همه ویژگی‌هاست (مثلاً `ph`, `cl_concentration` بررسی نمی‌شوند)
- مسیر `data/clean_data.csv` وجود نداشت و باید ایجاد می‌شد
- پتانسیل بالایی برای تبدیل این فایل به pipeline قابل تست وجود دارد

---

## تغییرات انجام شده:
- اجرای pipeline روی فایل نمونه `dataset/sample_data.csv`
- بررسی خروجی نهایی تمیز و ذخیره در فایل جدید
- آماده‌سازی فایل برای ارزیابی مدل در روز آینده

---

##  برنامه کاری فردا – ورود به مرحله مدل‌سازی

###  اولویت‌های روز سوم:
1. بررسی اسکریپت آموزش مدل (احتمالاً در مسیر `Scripts/train_model.py`)
2. آموزش مدل پایه (XGBoost یا Regression ساده) روی داده‌های تمیزشده
3. ارزیابی مدل با RMSE, MAE
4. ذخیره مدل نهایی در مسیر `models/`

---

